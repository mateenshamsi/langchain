{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3607705e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Hello World')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader \n",
    "loader=TextLoader('speech.txt') \n",
    "text_documents=loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3612e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in d:\\gen-ai\\venv\\lib\\site-packages (5.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Reading a pdf\n",
    "%pip install pypdf \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('abcd1.pdf')\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff44181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a1c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in .\\venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\venv\\lib\\site-packages (from bs4) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in .\\venv\\lib\\site-packages (from beautifulsoup4->bs4) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Web loader \n",
    "%pip install bs4\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader=WebBaseLoader(web_paths=(\"https://cal.com/divyansharma\",),\n",
    "              bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "              class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "              )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23637b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://cal.com/divyansharma'}, page_content='')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import ArxivLoader \n",
    "docs = ArxivLoader(query=\"1706.03762\",load_max_docs=2).load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e407a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of docs: <class 'list'>\n",
      "Type of first element: <class 'langchain_core.documents.base.Document'>\n",
      "First element attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'get_lc_namespace', 'id', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'metadata', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'page_content', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'type', 'update_forward_refs', 'validate']\n",
      "['ABDULMATEEN MUBIN SHAMSI\\nmatinshamsi16@gmail.com 9998304067 abdulmateen-shamsi mateenshamsi\\nWORK EXPERIENCE\\nFreelance Developer\\nFreelance Web Developer May 2025 - Present\\n• Built a full-stack web application using Next.js for frontend and NestJS for backend with modular, scalable \\narchitecture.\\n• Designed RESTful APIs in NestJS and consumed them using Axios in Next.js with proper error handling and \\nloading states.\\n• Integrated PostgreSQL with Prisma  enabling eﬃcient data modeling and querying.\\nDevx Commerce\\nJunior Software Developer August 2024 - January 2025\\n• Implemented a high-performance website for a digital marketing agency using Astro.js, React, and Tailwind \\nCSS\\n• Optimized the site for speed and SEO, ensuring fast load times and better search engine visibility\\n• Collaborated with cross-functional teams, including QA, to ensure quality assurance and timely project \\ndelivery\\nEDUCATION\\nSarvajanik College Of Engineering And Technology\\nB.Tech in A.I. & D.S. - 8.60 CGPA October 2021 - June 2025\\n• Learned fundamentals of programming, data structures, and algorithms.\\n• Gained hands-on experience with machine learning models and libraries like Scikit-learn.\\n• Covered data preprocessing, model evaluation, and deployment basics.\\nPROJECTS\\nBlogify July 2024 - August 2024\\n• Built a full-stack blog application using the MERN stack, enabling users to create, edit, and delete posts with \\nimage uploads.\\n• Integrated AWS S3 for storing blog images securely using Multer and pre-signed URLs for eﬃcient ﬁle \\nhandling.\\nThreadify June 2024 - July 2024\\n• Developed a social media web app inspired by Threads using Next.js, with robust data validation through \\nZod and UI components built using Shadcn UI for a polished user experience.\\nRecipeShare February 2024 - March 2024\\n• Developed a recipe sharing web application using Express.js and EJS templating, enabling users to create, \\nshare, and browse recipes with dynamic server-side rendering.\\nSKILLS\\n• Frontend: Next.js, React, Tailwind CSS, Shadcn UI\\n• Backend: NestJS, Node.js, Express, MongoDB, REST APIs\\n• Languages: JavaScript, TypeScript, Python\\n• Tools & Platforms: AWS S3, Git, Docker, Vercel,Linux\\n• Validation & Testing: Zod, Jest\\n• Others: GraphQL, WebSockets, Prisma']\n"
     ]
    }
   ],
   "source": [
    "# Solution 1: If docs contains Document objects, extract the text content\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# If your docs are Document objects with page_content attribute\n",
    "if hasattr(docs[0], 'page_content'):\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)\n",
    "    final_documents = text_splitter.create_documents(texts)\n",
    "\n",
    "# Solution 2: If docs are already Document objects, use split_documents instead\n",
    "elif hasattr(docs[0], 'page_content'):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)\n",
    "    final_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Solution 3: If docs contains plain strings\n",
    "else:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)\n",
    "    final_documents = text_splitter.create_documents(docs)\n",
    "\n",
    "# Debug: Check what type of objects are in your docs\n",
    "print(f\"Type of docs: {type(docs)}\")\n",
    "print(f\"Type of first element: {type(docs[0])}\")\n",
    "print(f\"First element attributes: {dir(docs[0])}\")\n",
    "\n",
    "# Alternative approach: Convert everything to strings first\n",
    "docs_as_strings = []\n",
    "for doc in docs:\n",
    "    if hasattr(doc, 'page_content'):\n",
    "        docs_as_strings.append(doc.page_content)\n",
    "    elif isinstance(doc, str):\n",
    "        docs_as_strings.append(doc)\n",
    "    else:\n",
    "        docs_as_strings.append(str(doc))\n",
    "print(docs_as_strings)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "final_documents = text_splitter.create_documents(docs_as_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9998d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Devx Commerce\n",
      "Junior Software Developer August 2024 - January 2025\n",
      "• Implemented a high-performance website for a digital marketing agency using Astro.js, React, and Tailwind \n",
      "CSS\n",
      "• Optimized the site for speed and SEO, ensuring fast load times and better search engine visibility\n",
      "• Collaborated with cross-functional teams, including QA, to ensure quality assurance and timely project \n",
      "delivery\n",
      "EDUCATION\n",
      "Sarvajanik College Of Engineering And Technology'\n"
     ]
    }
   ],
   "source": [
    "print(final_documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff92bbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Hello World')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader('speech.txt')\n",
    "docs =loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b5c3a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='el'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\"\n",
    "with open(\"speech.txt\") as f: \n",
    "    speech = f.read()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2,chunk_overlap=1)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
